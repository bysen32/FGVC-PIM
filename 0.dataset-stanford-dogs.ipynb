{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Dogs 数据集\n",
    "\n",
    "数据集树形结构\n",
    "```\n",
    "./datasets/\n",
    "    stanford_dogs/\n",
    "        annotation.tar\n",
    "        Annotation/\n",
    "        Annotation/...\n",
    "\n",
    "        lists.tar\n",
    "        lists/\n",
    "            file_list.mat\n",
    "            test_list.mat\n",
    "            train_list.mat\n",
    "\n",
    "        images.tar\n",
    "        Images/\n",
    "            n02085620-Chihuahua/\n",
    "                n02085620_7.jpg\n",
    "                ...\n",
    "            ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "# 数据集下载相关常量\n",
    "DOWNLOAD_URL_PREFIX = 'http://vision.stanford.edu/aditya86/ImageNetDogs'\n",
    "\n",
    "DATASET_ROOT = \"./datasets/\"\n",
    "DATASET_NAME = \"stanford_dogs\"\n",
    "DATASET_PATH = join(DATASET_ROOT, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据集下载与解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_url, list_dir, list_files\n",
    "import tarfile\n",
    "\n",
    "IMAGES_PATH = join(DATASET_PATH, \"Images\")\n",
    "ANNOTATION_PATH = join(DATASET_PATH, \"Annotation\")\n",
    "\n",
    "def download():\n",
    "    if os.path.exists(IMAGES_PATH) and os.path.exists(ANNOTATION_PATH):\n",
    "        if len(os.listdir(IMAGES_PATH)) == len(os.listdir(ANNOTATION_PATH)) == 120:\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "    for tar_filename in ['annotation.tar', 'lists.tar', 'images.tar']:\n",
    "        tar_file_path = join(DATASET_PATH, tar_filename)\n",
    "        if not os.path.exists(tar_file_path):\n",
    "            url = DOWNLOAD_URL_PREFIX + '/' + tar_filename\n",
    "            download_url(url, DATASET_PATH, tar_filename, None)\n",
    "\n",
    "            print('Extracting downloaded file: ' + tar_file_path)\n",
    "            with tarfile.open(tar_file_path, 'r') as tar_file:\n",
    "                tar_file.extractall(DATASET_PATH)\n",
    "\n",
    "        # os.remove(DATASET_PATH)\n",
    "\n",
    "download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 训练集 与 测试集 分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import shutil\n",
    "\n",
    "stage2file = {\n",
    "    \"train\" : \"train_list.mat\",\n",
    "    \"test\" : \"test_list.mat\",\n",
    "}\n",
    "\n",
    "for stage, file in stage2file.items():\n",
    "    split_file = join(DATASET_PATH, \"lists\", file)\n",
    "    data = scipy.io.loadmat(split_file)[\"annotation_list\"]\n",
    "    split = [it[0][0] for it in data]\n",
    "\n",
    "    for file_path in split:\n",
    "        dir_name, file_name = file_path.split(\"/\")\n",
    "        if not os.path.isdir(join(DATASET_PATH, stage, dir_name)):\n",
    "            os.makedirs(join(DATASET_PATH, stage, dir_name))\n",
    "        file1 = join(DATASET_PATH, \"Images\", file_path+\".jpg\")\n",
    "        file2 = join(DATASET_PATH, stage, file_path+\".jpg\")\n",
    "        shutil.copy(file1, file2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a5b314f07aa0d4f663e203b3e69440534a163bbc46a9857c85f54faef45d0d1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
